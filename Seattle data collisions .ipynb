{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "## Applied Data Science IBM-Coursera course\n### This notebook will be mainly used for the capstone project:\n### \"A safer car driving environment\"\n"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Hello Capstone Project Course!\n"
                }
            ],
            "source": "import pandas as pd\nimport numpy as np\nprint(\"Hello Capstone Project Course!\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Description of the problem and discussion of the background \nSevere vehicle collisions may result in the loss of human lives and leave survivors with serious physical, psychological and economic problems. \n\nSevere traffic accidents may have an important impact on the community at the social and economic levels. \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In this capstone project I will take advantage of machine learning techniques to analyze the historical data of vehicle collisions in Seattle, WA. \n\nI will seek to identify factors that contribute to the occurrence of severe vehicle collisions and then I will use this information to generate a \n\nmodel that predicts the different accidents' severity under specified conditions (described in the Data section;  among others, weather and road \n\nconditions, speed of the vehicle, drivers under the influence of drugs).\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The information generated in this project will be of interest to politicians, transportation and health authorities, insurance companies, travel \n\nagencies, auto makers and community leaders .\n\nThey will be in a position to contribute to the wellbeing of the community by making educated decisions aiming at reducing the frequency of vehicle \n\ncollisions that result in loss of human lives and/or people with severe injuries.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Importantly, drivers will have the opportunity to plan their trips more carefully by having access to information on weather and road conditions and \n\nother factors that increase the probability of getting involved in a severe car accident.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Description of the data and how it will be used to solve the problem\n\nData about vehicle collision in the area of Seattle, WA, will be obtained from the Seattle Geodata website \n\nhttps://data-seattlecitygis.opendata.arcgis.com/datasets/5b5c745e0f1f48e7a53acec63a0022ab_0\n\nThe document __\u201cCollisions.csv\u201d__ contains data about all types of vehicles collisions that occurred in Seattle, WA, from 2004 to 2018. \n\nThis collection of historical data covers 195,103 reported Collisions and includes the severity of the accidents as well as numerical and categorical values corresponding to 37 attributes. \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The values in the column __\u201cSEVERITYCODE\u201d__, the target variable, show the severity of the vehicle collision. \n\nThese are the attributes (subjected to further selection) and their description that I will use to generate a model that predicts the severity of vehicle collision:  \n  \n  \n   __PEDCOUNT__ (The number of pedestrians involved in the collision)  \n     \n   __PEDCYLCOUNT__ (The number of bicycles involved in the collision)  \n     \n   __VEHCOUNT__ (The number of vehicles involved in the collision)  \n     \n   __INJURIES__ (The number of total injuries in the collision)  \n     \n   __SERIOUSINJURIES__ (The number of serious injuries in the collision)  \n     \n   __FATALITIES__ (The number of fatalities in the collision)  \n     \n   __INCDATE__ (The date of the incident)  \n     \n   __INCDTTM__ (The date and time of the incident)  \n     \n   __INATTENTIONIND__ (Whether or not collision was due to inattention)  \n     \n   __UNDERINFL__ (Whether or not a driver involved was under the influence of drugs or alcohol)  \n     \n   __WEATHER__ (A description of the weather conditions during the time of the collision)  \n     \n   __ROADCOND__ (The condition of the road during the collision)  \n     \n   __LIGHTCOND__ (The light conditions during the collision)  \n     \n   __SPEEDING__ (Whether or not speeding was a factor in the collision).  \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As a __first step__, I will get basic insights from the data:\n  \na) Check data types (potential info and type mismatch, compatibility with python methods) \n  \nb) Use de describe(include = \u201call\u201d) method to get a statistical summary of each column to learn about the distribution of numerical and categorical      data in that column.  \n  \nc) info() method will provide a concise summary of the dataframe. \n  \n  \n__Very important__: \n  \nIt is evident that the observations in the target variable __\u201cSEVERITYCODE\u201d__ are not balanced. \n  \nWe have the following distribution for the 199,910 accidents whose severity code is known: \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "| Severity code | Number of events | Percentage |\n| --- | --- | --- |\n| 1 (property damage) | 136,672   | 68.86 |\n| --- | --- | --- |\n| 2 (injury) | 58,783   | 29.40  |\n| --- | --- | --- |\n| 2b (serious injury) | 3,105   | 1.55 |\n| --- | --- | --- |\n| 3 (fatality) | 350   | 0.17 |\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Machine learning algorithms are designed to maximize overall accuracy by default. \n  \nHence, the problem when using an unbalanced dataset is that model accuracy will be high simply because the model is detecting the most abundant value.  \n  \nTo solve this issue I will follow the information given at https://elitedatascience.com/imbalanced-classes  and use the __resampling__ module\nfrom __Scikit-Learn__.  \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "To apply supervised learning techniques to classify vehicle collisions on the basis of the severity of the accident, I will replace the numerical \n  \nvalues in the __\u201cSEVERITYCODE\u201d__ column with categorical values (i.e. __low__: property damage and minor personal injuries, __high__: serious injuries and fatalities).\n  \nI will try several of following the suggested strategies for handling imbalanced classes in machine learning: "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "1. Up-sample the minority class\n2. Down-sample the majority class\n3. Change performance metric\n4. Penalize algorithms (cost-sensitive training)\n5. Use tree-based algorithms. \n                           \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "At the __pre-processing__ stage I will focus on:  \n  \n   a) Identification and handling missing values.  \n   b) Standardize the values into the same format , or unit, or convention.  \n   c) Data normalization to bring all data into a similar range for more useful comparison.  \n   d) Data binning for comparison between groups of data.  \n   e) Convert categorical values into numerical values to make statistical modeling easier.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "I will use the attributes that have the greatest impact on the value of the __\u201cSEVERITYCODE\u201d__, as\njudged by the __Person Correlation Coefficien__ and __P-value__,  to generate a model that  \n  \npredicts the different accidents\u00b4 severity.  \n  \nThe following algorithms will be used: \n  \n   __KNN  \n      Decision Tree  \n      Support Vector Machine  \n      Logistic Regression__\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "To provide a more accurate evaluation on __out-of-sample accuracy__, train and test datasets will be \ngenerated using __train_test_split__.  \n  \nModels will be generated with the train set and tested with the test set. \n\nFinally, models will be evaluated using different metrics: __Jaccard index__; __Confusion matrix__ indicating \n__Precision__, __Recall__ and __F1-score__; __LogLoss__."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "__Thanks for reviewing my work!__  \n__I will appreciate your suggestions.__"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}